{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set true if you want images to display\n",
    "\n",
    "display = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        if display:\n",
    "            # Draw and display the corners\n",
    "            img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "            cv2.imshow('img',img)\n",
    "            cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Camera calibration parameters\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test checkerboard undistortion\n",
    "\n",
    "def cal_undistort(img, mtx, dist):\n",
    "    # Use cv2.calibrateCamera() and cv2.undistort()\n",
    "    undist = cv2.undistort(img, mtx, dist)\n",
    "    return undist\n",
    "\n",
    "if display:\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        undistorted = cal_undistort(img, mtx, dist)\n",
    "        cv2.imshow('img',undistorted)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    # Read in an image\n",
    "    img = cv2.imread('test_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check undistortion on test images of roads\n",
    "\n",
    "if display:\n",
    "    images = glob.glob('./test_images/*.jpg')\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        undistorted = cal_undistort(img, mtx, dist)\n",
    "        cv2.imshow('img', undistorted)\n",
    "        cv2.waitKey(5000)\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from numpy.linalg import inv\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def get_binary_image(img, binary='grey'):\n",
    "    if binary == 'grey':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    elif binary == 'HLS_S':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2HLS)[:,:,2]\n",
    "    elif binary == 'HSV_V':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)[:,:,2]\n",
    "    elif binary == 'RGB_R':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)[:,:,0]\n",
    "    else:\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255, binary='grey'):\n",
    "    grey = get_binary_image(img, binary)\n",
    "    \n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(grey, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(grey, cv2.CV_64F, 0, 1))\n",
    "        \n",
    "    scaled_sobel = 255 * abs_sobel / np.max(abs_sobel)\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255), binary='grey'):\n",
    "    grey = get_binary_image(img, binary)\n",
    "    \n",
    "    sobel_x = np.absolute(cv2.Sobel(grey, cv2.CV_64F, 1, 0))\n",
    "    sobel_y = np.absolute(cv2.Sobel(grey, cv2.CV_64F, 0, 1))\n",
    "    sobel_xy = np.sqrt((sobel_x ** 2) + (sobel_y ** 2))\n",
    "        \n",
    "    scaled_sobel = 255 * sobel_xy / np.max(sobel_xy)\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2), binary='grey'):\n",
    "    grey = get_binary_image(img, binary)\n",
    "    \n",
    "    sobel_x = np.absolute(cv2.Sobel(grey, cv2.CV_64F, 1, 0))\n",
    "    sobel_y = np.absolute(cv2.Sobel(grey, cv2.CV_64F, 0, 1))\n",
    "        \n",
    "    gradient_sobel = np.arctan2(sobel_y, sobel_x)\n",
    "    \n",
    "    binary_output = np.zeros_like(gradient_sobel)\n",
    "    binary_output[(gradient_sobel >= thresh[0]) & (gradient_sobel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def colour_threshold(img, thresh=(0, np.pi/2), binary='grey'):\n",
    "    grey = get_binary_image(img, binary)\n",
    "    \n",
    "    binary_output = np.zeros_like(grey)\n",
    "    binary_output[(grey >= thresh[0]) & (grey <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def window_mask(width, height, img_ref, center, level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    start_y = int(img_ref.shape[0] - (level + 1) * height)\n",
    "    end_y = int(img_ref.shape[0] - level * height)\n",
    "    start_x = max(0, int(center - width/2))\n",
    "    end_x = min(int(center + width/2), img_ref.shape[1])\n",
    "    \n",
    "    output[start_y:end_y, start_x:end_x] = 1\n",
    "    return output\n",
    "\n",
    "def find_window_centroids(image, window_width, window_height, margin):\n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    levels = int(image.shape[0] / window_height)\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the \n",
    "    # vertical image slice and then np.convolve the vertical image slice with the window template \n",
    "    \n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    \n",
    "    y_start = int(3*image.shape[0]/4)\n",
    "    x_mid = int(image.shape[1]/2)\n",
    "    \n",
    "    l_sum = np.sum(image[y_start:, :x_mid], axis=0)\n",
    "    l_centre = np.argmax(np.convolve(window, l_sum)) - window_width/2\n",
    "    r_sum = np.sum(image[y_start:, x_mid:], axis=0)\n",
    "    r_centre = np.argmax(np.convolve(window, r_sum)) - window_width/2 + int(image.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    \n",
    "    window_centroids.append((l_centre, r_centre))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    \n",
    "    for level in range(1, levels):\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        y_level_start = int(image.shape[0] - (level + 1) * window_height)\n",
    "        y_level_end = int(image.shape[0] - level * window_height)\n",
    "        \n",
    "        image_layer = np.sum(image[y_level_start:y_level_end, :], axis=0)\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        \n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        # Use window_width/2 as offset because convolution signal reference is \n",
    "        # at right side of window, not center of window\n",
    "        \n",
    "        offset = window_width / 2\n",
    "        l_min_index = int(max(l_centre + offset - margin, 0))\n",
    "        l_max_index = int(min(l_centre + offset + margin, image.shape[1]))\n",
    "\n",
    "        # Update l_centre\n",
    "        if np.max(conv_signal[l_min_index:l_max_index]) != 0:\n",
    "            l_centre = np.argmax(conv_signal[l_min_index:l_max_index]) + l_min_index - offset\n",
    "        \n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        \n",
    "        r_min_index = int(max(r_centre + offset - margin, 0))\n",
    "        r_max_index = int(min(r_centre + offset + margin, image.shape[1]))\n",
    "\n",
    "        # Update r_centre\n",
    "        if np.max(conv_signal[r_min_index:r_max_index]) != 0:\n",
    "            r_centre = np.argmax(conv_signal[r_min_index:r_max_index]) + r_min_index - offset\n",
    "        \n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_centre, r_centre))\n",
    "\n",
    "    return window_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process image function\n",
    "\n",
    "def process_image(img):\n",
    "    # x side offsets for lane projections \n",
    "    \n",
    "    offset = 250\n",
    "\n",
    "    # Coordinates of trapezoid for projection\n",
    "    \n",
    "    #src = np.float32([(598, 446), (683, 446), (1064, 681), (241, 681)])\n",
    "    #src = np.float32([(553, 475), (731, 475), (1064, 681), (238, 681)])\n",
    "    src = np.float32([(575, 460), (706, 460), (1064, 681), (238, 681)])\n",
    "    \n",
    "    # Coordinates of projected lane with x side offsets\n",
    "    \n",
    "    dst = np.float32([(offset, 0), (1280 - offset, 0), \\\n",
    "                      (1280 - offset, 720), (offset, 720)])\n",
    "\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    # Search window settings\n",
    "    \n",
    "    window_width = 50 \n",
    "    window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "    margin = 50 # How much to slide left and right for searching\n",
    "\n",
    "    undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "    thresh_x = abs_sobel_thresh(undistorted, 'x', 35, 255, 'grey')\n",
    "    thresh_y = abs_sobel_thresh(undistorted, 'y', 35, 255, 'grey')\n",
    "    S_thresh = colour_threshold(undistorted, (150, 255), 'HLS_S')\n",
    "    V_thresh = colour_threshold(undistorted, (150, 255), 'HSV_V')\n",
    "\n",
    "    # Combined threshold \n",
    "    #combined_thresh = np.uint8((thresh_x == 1) & (thresh_y == 1))\n",
    "    combined_thresh = np.uint8(((thresh_x == 1) & (thresh_y == 1)) | ((S_thresh == 1) & (V_thresh == 1)))\n",
    "    color_warp = np.dstack((combined_thresh, combined_thresh, combined_thresh)) * 255\n",
    "    #return color_warp\n",
    "    \n",
    "    img_size = (combined_thresh.shape[1], combined_thresh.shape[0])\n",
    "    \n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    \n",
    "    warped = cv2.warpPerspective(combined_thresh, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    window_centroids = find_window_centroids(warped, window_width, window_height, margin)\n",
    "\n",
    "    # If we found any window centers\n",
    "    \n",
    "    if len(window_centroids) > 0:\n",
    "        left_x = np.array([])\n",
    "        right_x = np.array([])\n",
    "        left_y = np.array([])\n",
    "        right_y = np.array([])\n",
    "\n",
    "        # Points used to draw all the left and right windows\n",
    "        \n",
    "        l_points = np.zeros_like(warped)\n",
    "        r_points = np.zeros_like(warped)\n",
    "\n",
    "        # Go through each level and draw the windows\n",
    "        for level in range(0, len(window_centroids)):\n",
    "\n",
    "            # Window_mask is a function to draw window areas\n",
    "\n",
    "            l_mask = window_mask(window_width, window_height, warped, window_centroids[level][0], level)\n",
    "            r_mask = window_mask(window_width, window_height, warped, window_centroids[level][1], level)\n",
    "\n",
    "            # Add graphic points from window mask here to total pixels found \n",
    "\n",
    "            l_points[(l_points == 255) | ((l_mask == 1))] = 255\n",
    "            r_points[(r_points == 255) | ((r_mask == 1))] = 255\n",
    "\n",
    "            # Get indices of white points within each window\n",
    "            \n",
    "            window_points_l = np.where((l_points == 255) & ((l_mask == 1)))\n",
    "            left_x = np.append(left_x, window_points_l[1])\n",
    "            left_y = np.append(left_y, window_points_l[0])\n",
    "            window_points_r = np.where((r_points == 255) & ((r_mask == 1)))\n",
    "            right_x = np.append(right_x, window_points_r[1])\n",
    "            right_y = np.append(right_y, window_points_r[0])\n",
    "\n",
    "        ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "\n",
    "        # Use these points to fit a second order polynomial to pixel positions \n",
    "        left_fit = np.polyfit(left_y, left_x, 2)\n",
    "        left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "        right_fit = np.polyfit(right_y, right_x, 2)\n",
    "        right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]    \n",
    "\n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        \n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/720 # meters per pixel in x dimension\n",
    "\n",
    "        # Get camera centre x value in warped image\n",
    "        \n",
    "        camera_centre_x = (640 - src[3][0]) / (src[2][0] - src[3][0])\n",
    "        camera_centre_x_warped = camera_centre_x * (780) + offset # 720 is the number of pixels the lane fills at the bottom of frame\n",
    "            \n",
    "        base_left_x = left_fit[0] * img_size[1] ** 2 + left_fit[1] * img_size[1] + left_fit[2]\n",
    "        base_right_x = right_fit[0] * img_size[1] ** 2 + right_fit[1] * img_size[1] + right_fit[2]    \n",
    "        \n",
    "        dist_from_centre = round((camera_centre_x_warped - 0.5 * (base_right_x + base_left_x)) * xm_per_pix, 2)\n",
    "        \n",
    "        # Fit new polynomials to x,y in world space\n",
    "        \n",
    "        left_fit_cr = np.polyfit(left_y * ym_per_pix, left_x * xm_per_pix, 2)\n",
    "        right_fit_cr = np.polyfit(right_y * ym_per_pix, right_x * xm_per_pix, 2)\n",
    "        \n",
    "        # Calculate the new radii of curvature\n",
    "        \n",
    "        radius_left = (1 + (2 * left_fit_cr[0] * img_size[1] * ym_per_pix + left_fit_cr[1]) ** 2) ** 1.5 / \\\n",
    "            abs(2 * left_fit_cr[0])\n",
    "        radius_right = (1 + (2 * right_fit_cr[0] * img_size[1] * ym_per_pix + right_fit_cr[1]) ** 2) ** 1.5 / \\\n",
    "            abs(2 * right_fit_cr[0])\n",
    "            \n",
    "        average_radius = 0.5 * (radius_left + radius_right)\n",
    "        \n",
    "        # Create an image to draw the lines on\n",
    "        warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        newwarp = cv2.warpPerspective(color_warp, inv(M), img_size) \n",
    "        # Combine the result with the original image\n",
    "        result = cv2.addWeighted(undistorted, 1, newwarp, 0.3, 0)\n",
    "        \n",
    "        cv2.putText(result, \"Radius of curvature: \" + str(average_radius) + \"m\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255))\n",
    "        cv2.putText(result, \"Vehicle is \" + str(dist_from_centre) + \" m right of centre\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255))\n",
    "        \n",
    "        return result\n",
    "    else:\n",
    "        return np.array(cv2.merge((warped,warped,warped)), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/test_07.mp4\n",
      "[MoviePy] Writing video test_videos_output/test_07.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [05:12<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/test_07.mp4 \n",
      "\n",
      "CPU times: user 7min 19s, sys: 1min 28s, total: 8min 48s\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "write_output = 'test_videos_output/test_07.mp4'\n",
    "\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "#clip1 = VideoFileClip(\"./project_video.mp4\").subclip(21,24)\n",
    "clip1 = VideoFileClip(\"./project_video.mp4\")\n",
    "\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(write_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/test_02.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(write_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
